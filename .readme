Формат файла data_task3.csv: login tuid docid jud cjud.

Пояснение к формату: 
login — логин асессора; 
uid — id асессора (user id); 
docid — id оцениваемого документа (document id); 
jud — оценка асессора (judgement); 
cjud — правильная оценка (correct judgement); 
разделитель — табуляция \t.

Оценки могут принимать значение [0, 1], т.е. задание, которое сделали асессоры, имеет бинарную шкалу.

Используя данные об оценках, установите, какие асессоры хуже всего справились с заданием. 
На какие показатели вы ориентировались и какие метрики вы использовали для ответа на этот вопрос? 
Можно ли предложить какие-то новые метрики для подсчета качества асессоров с учетом природы оценок у этого бинарного задания?


*************************
Решение:
Просто идти по таблице сверху вниз и считать, сколько раз jud и cjud совпали для каждого uid.
Составить рейтинг асессоров путем пузырьковой сортировки чтобы было кол-во jud и cjud и по кол-во правильных ответов крутой в топе, тупой в попе.